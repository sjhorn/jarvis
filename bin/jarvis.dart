import 'dart:async';
import 'dart:io';

import 'package:jarvis_dart/src/cli/config_loader.dart';
import 'package:jarvis_dart/src/cli/model_downloader.dart';
import 'package:jarvis_dart/src/cli/package_assets.dart';
import 'package:jarvis_dart/src/logging.dart';
import 'package:jarvis_dart/src/voice_assistant.dart';
import 'package:logging/logging.dart';

/// JARVIS version
const version = '1.0.0';

/// Default JARVIS system prompt.
const defaultSystemPrompt = '''
You are JARVIS, an advanced AI assistant inspired by the AI from Iron Man.
You are helpful, witty, and occasionally sarcastic but always respectful.
Keep your responses concise and conversational since they will be spoken aloud.
''';

/// Gets the JARVIS home directory (~/.jarvis).
String getJarvisHome() {
  final home = Platform.environment['HOME'] ??
      Platform.environment['USERPROFILE'] ??
      '.';
  return '$home/.jarvis';
}

/// Prints usage information.
void printUsage() {
  print('''
JARVIS Voice Assistant v$version

Usage: jarvis [command] [options]

Commands:
  setup               Download ML models and create default config
  version             Show version information
  (none)              Run the voice assistant

Options:
  -c, --config <path>   Path to YAML configuration file
                        (default: ~/.jarvis/config.yaml)
  -v, --verbose         Enable verbose logging (INFO level)
  -d, --debug           Enable debug logging (FINE level, includes timing)
  --trace               Enable trace logging (FINEST level, very verbose)
  -q, --quiet           Suppress all logging output
  --record              Enable session recording (saves to ./sessions/)
  --record-dir <path>   Enable recording with custom directory
  -h, --help            Show this help message

Environment Variables (alternative to config file):
  WHISPER_MODEL_PATH      Path to Whisper model file
  WHISPER_EXECUTABLE      Path to whisper-cli executable
  LLAMA_MODEL_REPO        Hugging Face model repo (e.g., ggml-org/gemma-3-1b-it-GGUF)
  LLAMA_EXECUTABLE        Path to llama-cli executable
  WAKEWORD_ENCODER_PATH   Path to wake word encoder ONNX model
  WAKEWORD_DECODER_PATH   Path to wake word decoder ONNX model
  WAKEWORD_JOINER_PATH    Path to wake word joiner ONNX model
  WAKEWORD_TOKENS_PATH    Path to wake word tokens file
  WAKEWORD_KEYWORDS_FILE  Path to wake word keywords file
  TTS_MODEL_PATH          Path to TTS model ONNX file
  TTS_TOKENS_PATH         Path to TTS tokens file
  TTS_DATA_DIR            Path to espeak-ng-data directory
  SHERPA_LIB_PATH         Path to sherpa-onnx native library
  SYSTEM_PROMPT           (Optional) Custom system prompt

Quick Start:
  # First-time setup (downloads ~150MB models)
  jarvis setup

  # Edit configuration (add whisper/llama paths)
  vim ~/.jarvis/config.yaml

  # Run
  jarvis
''');
}

/// Runs the setup command.
Future<void> runSetup(List<String> args) async {
  print('');
  print('='.padRight(50, '='));
  print('  JARVIS Setup');
  print('='.padRight(50, '='));
  print('');

  final jarvisHome = getJarvisHome();
  final modelsDir = '$jarvisHome/models';
  final configPath = '$jarvisHome/config.yaml';

  // Download models
  final downloader = ModelDownloader(
    modelsDir: modelsDir,
    onProgress: (msg) => print(msg),
  );

  try {
    await downloader.downloadAll();
  } on ModelDownloadException catch (e) {
    stderr.writeln('');
    stderr.writeln('Download failed: ${e.message}');
    exit(1);
  }

  // Create default config if not exists
  if (!await File(configPath).exists()) {
    print('');
    print('Creating default configuration...');

    final modelPaths = downloader.getModelPaths();

    // Get bundled assets paths
    final ackDir = await PackageAssets.getAcknowledgmentsDir();
    final bargeInDir = await PackageAssets.getBargeInDir();

    // Detect sherpa library
    final sherpaLib = await _detectSherpaLib();

    final configContent = '''
# JARVIS Configuration
# Generated by: jarvis setup
# Edit paths below to match your system

# Whisper (speech-to-text) - REQUIRED
# Download from: https://github.com/ggerganov/whisper.cpp
whisper_model_path: /path/to/whisper.cpp/models/ggml-base.en.bin
whisper_executable: /path/to/whisper.cpp/build/bin/whisper-cli

# LLaMA (language model) - REQUIRED
# Install: brew install llama.cpp OR build from source
llama_model_repo: ggml-org/gemma-3-1b-it-GGUF
llama_executable: /opt/homebrew/bin/llama-cli

# Wake word detection (downloaded by setup)
wakeword_encoder_path: ${modelPaths['wakeword_encoder_path']}
wakeword_decoder_path: ${modelPaths['wakeword_decoder_path']}
wakeword_joiner_path: ${modelPaths['wakeword_joiner_path']}
wakeword_tokens_path: ${modelPaths['wakeword_tokens_path']}
wakeword_keywords_file: ${modelPaths['wakeword_keywords_file']}

# TTS (text-to-speech) - downloaded by setup
tts_model_path: ${modelPaths['tts_model_path']}
tts_tokens_path: ${modelPaths['tts_tokens_path']}
tts_data_dir: ${modelPaths['tts_data_dir']}

# Sherpa ONNX native library
${sherpaLib != null ? 'sherpa_lib_path: $sherpaLib' : '# sherpa_lib_path: auto  # Auto-detect from pub cache'}

# Audio assets (bundled with package)
${ackDir != null ? 'acknowledgment_dir: $ackDir' : '# acknowledgment_dir: bundled  # Use bundled assets'}
${bargeInDir != null ? 'barge_in_dir: $bargeInDir' : '# barge_in_dir: bundled  # Use bundled assets'}

# Optional settings
# system_prompt: "You are JARVIS..."
# silence_threshold: 0.01
# silence_duration_ms: 800
# max_history_length: 10
# enable_follow_up: true
# enable_barge_in: true
''';

    await Directory(jarvisHome).create(recursive: true);
    await File(configPath).writeAsString(configContent);
    print('Created: $configPath');
  } else {
    print('');
    print('Configuration already exists: $configPath');
  }

  print('');
  print('='.padRight(50, '='));
  print('  Setup Complete!');
  print('='.padRight(50, '='));
  print('');
  print('Next steps:');
  print('');
  print('1. Edit the configuration file:');
  print('   vim $configPath');
  print('');
  print('2. Set paths for whisper-cli and llama-cli');
  print('');
  print('3. Run JARVIS:');
  print('   jarvis');
  print('');
}

/// Attempts to auto-detect sherpa-onnx library in pub cache.
Future<String?> _detectSherpaLib() async {
  final home = Platform.environment['HOME'] ??
      Platform.environment['USERPROFILE'] ??
      '.';

  // Check pub cache locations
  final cacheLocations = [
    '$home/.pub-cache/hosted/pub.dev',
    '$home/.pub-cache/hosted/pub.dartlang.org',
  ];

  for (final cacheDir in cacheLocations) {
    final dir = Directory(cacheDir);
    if (!await dir.exists()) continue;

    await for (final entity in dir.list()) {
      if (entity is Directory && entity.path.contains('sherpa_onnx')) {
        // Look for the native lib inside
        final libDir = Directory('${entity.path}/lib');
        if (await libDir.exists()) {
          return libDir.path;
        }
      }
    }
  }

  return null;
}

Future<void> main(List<String> arguments) async {
  // Handle commands first
  if (arguments.isNotEmpty) {
    switch (arguments[0]) {
      case 'setup':
        await runSetup(arguments.skip(1).toList());
        return;
      case 'version':
        print('JARVIS Voice Assistant v$version');
        return;
    }
  }

  // Parse command line arguments
  String? configPath;
  var logLevel = Level.WARNING; // Default: only warnings and errors
  var recordingEnabled = false;
  String? recordDir;

  for (var i = 0; i < arguments.length; i++) {
    final arg = arguments[i];
    if (arg == '-h' || arg == '--help') {
      printUsage();
      exit(0);
    } else if (arg == '-c' || arg == '--config') {
      if (i + 1 >= arguments.length) {
        stderr.writeln('Error: --config requires a path argument');
        exit(1);
      }
      configPath = arguments[i + 1];
      i++;
    } else if (arg == '-v' || arg == '--verbose') {
      logLevel = Level.INFO;
    } else if (arg == '-d' || arg == '--debug') {
      logLevel = Level.FINE;
    } else if (arg == '--trace') {
      logLevel = Level.FINEST;
    } else if (arg == '-q' || arg == '--quiet') {
      logLevel = Level.OFF;
    } else if (arg == '--record') {
      recordingEnabled = true;
    } else if (arg == '--record-dir') {
      if (i + 1 >= arguments.length) {
        stderr.writeln('Error: --record-dir requires a path argument');
        exit(1);
      }
      recordingEnabled = true;
      recordDir = arguments[i + 1];
      i++;
    }
  }

  // Initialize logging
  LogConfig.initialize(level: logLevel);

  // Load configuration with priority:
  // 1. --config flag
  // 2. ~/.jarvis/config.yaml (if exists)
  // 3. Environment variables
  AppConfig config;
  try {
    if (configPath != null) {
      print('Loading configuration from: $configPath');
      config = await ConfigLoader.fromYamlFile(configPath);
    } else {
      // Try default config location
      final defaultConfig = '${getJarvisHome()}/config.yaml';
      if (await File(defaultConfig).exists()) {
        print('Loading configuration from: $defaultConfig');
        config = await ConfigLoader.fromYamlFile(defaultConfig);
      } else {
        print('Loading configuration from environment variables...');
        config = ConfigLoader.fromEnvironment();
      }
    }
  } on ConfigException catch (e) {
    stderr.writeln('Configuration error: ${e.message}');
    stderr.writeln('');
    stderr.writeln('Run "jarvis setup" to download models and create config.');
    stderr.writeln('Run "jarvis --help" for usage information.');
    exit(1);
  }

  // Resolve bundled assets if needed
  var acknowledgmentDir = config.acknowledgmentDir;
  var bargeInDir = config.bargeInDir;

  if (acknowledgmentDir == null || acknowledgmentDir == 'bundled') {
    acknowledgmentDir = await PackageAssets.getAcknowledgmentsDir();
  }
  if (bargeInDir == null || bargeInDir == 'bundled') {
    bargeInDir = await PackageAssets.getBargeInDir();
  }

  // CLI args override config file values for recording
  final effectiveRecordingEnabled = recordingEnabled || config.recordingEnabled;
  final effectiveSessionDir = recordDir ?? config.sessionDir;

  // Apply default system prompt if not set
  final assistantConfig = VoiceAssistantConfig(
    whisperModelPath: config.whisperModelPath,
    whisperExecutablePath: config.whisperExecutablePath,
    llamaModelRepo: config.llamaModelRepo,
    llamaExecutablePath: config.llamaExecutablePath,
    wakeWordEncoderPath: config.wakeWordEncoderPath,
    wakeWordDecoderPath: config.wakeWordDecoderPath,
    wakeWordJoinerPath: config.wakeWordJoinerPath,
    wakeWordTokensPath: config.wakeWordTokensPath,
    wakeWordKeywordsFile: config.wakeWordKeywordsFile,
    ttsModelPath: config.ttsModelPath,
    ttsTokensPath: config.ttsTokensPath,
    ttsDataDir: config.ttsDataDir,
    sherpaLibPath: config.sherpaLibPath,
    acknowledgmentDir: acknowledgmentDir,
    systemPrompt: config.systemPrompt ?? defaultSystemPrompt,
    silenceThreshold: config.silenceThreshold,
    silenceDuration: config.silenceDuration,
    maxHistoryLength: config.maxHistoryLength,
    sentencePause: config.sentencePause,
    enableFollowUp: config.enableFollowUp,
    followUpTimeout: config.followUpTimeout,
    statementFollowUpTimeout: config.statementFollowUpTimeout,
    enableBargeIn: config.enableBargeIn,
    bargeInDir: bargeInDir,
    audioPlayer: config.audioPlayer,
    audioPlayerPath: config.audioPlayerPath,
    recordingEnabled: effectiveRecordingEnabled,
    sessionDir: effectiveSessionDir,
  );

  // Create voice assistant
  final assistant = VoiceAssistant(config: assistantConfig);

  // Set up graceful shutdown
  var shutdownRequested = false;
  final shutdownCompleter = Completer<void>();

  Future<void> shutdown() async {
    if (shutdownRequested) return;
    shutdownRequested = true;

    print('');
    print('Shutting down JARVIS...');

    try {
      await assistant.stop();
      await assistant.dispose();
      print('Goodbye!');
    } catch (e) {
      stderr.writeln('Error during shutdown: $e');
    }

    shutdownCompleter.complete();
  }

  // Handle SIGINT (Ctrl+C) and SIGTERM
  ProcessSignal.sigint.watch().listen((_) => shutdown());
  if (!Platform.isWindows) {
    ProcessSignal.sigterm.watch().listen((_) => shutdown());
  }

  // Subscribe to state changes
  assistant.stateStream.listen((state) {
    switch (state) {
      case AssistantState.idle:
        print('[State] Idle');
      case AssistantState.listeningForWakeWord:
        print('[State] Listening for wake word...');
      case AssistantState.listening:
        print('[State] Listening to you...');
      case AssistantState.processing:
        print('[State] Processing...');
      case AssistantState.speaking:
        print('[State] Speaking...');
      case AssistantState.awaitingFollowUp:
        print('[State] Awaiting your response...');
      case AssistantState.prompting:
        print('[State] Prompting...');
      case AssistantState.error:
        print('[State] Error occurred, recovering...');
    }
  });

  // Subscribe to transcriptions
  assistant.transcriptionStream.listen((transcription) {
    print('[You] $transcription');
  });

  // Subscribe to responses
  assistant.responseStream.listen((response) {
    print('[JARVIS] $response');
  });

  // Initialize and start
  try {
    print('');
    print('='.padRight(50, '='));
    print('  JARVIS Voice Assistant v$version');
    print('='.padRight(50, '='));
    print('');
    print('Initializing...');

    await assistant.initialize();
    print('Initialization complete.');
    print('');
    print('Say the wake word to start a conversation.');
    print('Press Ctrl+C to exit.');
    print('');

    await assistant.start();

    // Wait for shutdown signal
    await shutdownCompleter.future;
    exit(0);
  } on VoiceAssistantException catch (e) {
    stderr.writeln('');
    stderr.writeln('Failed to start JARVIS: ${e.message}');
    if (e.cause != null) {
      stderr.writeln('Cause: ${e.cause}');
    }
    stderr.writeln('');
    stderr.writeln('Please check your configuration and try again.');
    await assistant.dispose();
    exit(1);
  } catch (e, stackTrace) {
    stderr.writeln('');
    stderr.writeln('Unexpected error: $e');
    stderr.writeln(stackTrace);
    await assistant.dispose();
    exit(1);
  }
}
